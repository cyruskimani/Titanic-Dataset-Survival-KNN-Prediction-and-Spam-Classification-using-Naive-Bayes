{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 9 Moringa Core IP Cyrus Kimani Part 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1e_f7SmoDZtdTtTa1tEHuHA1FT0Tg66Y0",
      "authorship_tag": "ABX9TyNXSu/pknhxP6kj769aQLS3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyruskimani/Titanic-Dataset-Survival-KNN-Prediction-and-Spam-Classification-using-Naive-Bayes/blob/main/Week_9_Moringa_Core_IP_Cyrus_Kimani_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMlG5oYiTF0F"
      },
      "source": [
        "# Naive Bayes Classification for Spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96MvtNc0WQhR"
      },
      "source": [
        "# Defining The Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbhdyukWnaw"
      },
      "source": [
        "## a) Specifying the Question.\r\n",
        "\r\n",
        "Overview \r\n",
        "\r\n",
        "Spam messages are considered to be junk or illegitimate messages, as compared to genuine or legitimate messages. This project seeks to construct a spam filter which can be used to classify text messages as ham or spam.\r\n",
        "\r\n",
        "Research Question\r\n",
        "\r\n",
        "Build a model that determines whether or not a message is spam or not.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CskDyCtsXlhz"
      },
      "source": [
        "## b) Defining the Metrics for Success.\r\n",
        "\r\n",
        "The Accuracy score,f1 score, Precision and Confusion Matrix will be used to evaluate the prediction of the of models.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0Izx0hMgsdO"
      },
      "source": [
        "## c) Understanding the context.\r\n",
        "\r\n",
        "Spam messages are unwanted messages sent from unknown users or containing unsolicited information.\r\n",
        "\r\n",
        "This exercise focuses on spam messages and seeks to create a model which classifies messages as spam or ham.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3W9jyb_mmdj"
      },
      "source": [
        "## d) Recording the Experimental Design.\r\n",
        "\r\n",
        "The experimental design for this project will be composed of Exploratory Data Analysis and Classification Models as shown below.\r\n",
        "\r\n",
        "Exploratory Data Analysis.\r\n",
        "\r\n",
        "* Univariate Analysis.\r\n",
        "\r\n",
        "Classification\r\n",
        "\r\n",
        "* Naive Bayes Classifier\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prmju_7CtBQc"
      },
      "source": [
        "# Importing Libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zBHWynI17sa"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8bRyFi_2tcN",
        "outputId": "fa2d9ab9-04f5-407c-c7d7-ab581573cb9c"
      },
      "source": [
        "!pip install pydataset "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydataset in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pydataset) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pydataset) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->pydataset) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pydataset) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pydataset) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3El8xrWUmg7"
      },
      "source": [
        "# Loading the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "0_pvHdCF1nI1",
        "outputId": "f6d1c802-6dee-409d-de67-29a9c7da8f7a"
      },
      "source": [
        "#Read the dataset\r\n",
        "from pydataset import data\r\n",
        "spam=pd.read_csv('/content/drive/MyDrive/Moringa Core Module 2 Regression/spambase.data',header=None)\r\n",
        "spam.sample(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.009</td>\n",
              "      <td>4.906</td>\n",
              "      <td>95</td>\n",
              "      <td>1310</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1351</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6.718</td>\n",
              "      <td>33</td>\n",
              "      <td>215</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0     1    2    3     4    5   ...     52     53     54  55    56  57\n",
              "1020  0.05  0.05  0.4  0.0  0.34  0.0  ...  0.079  0.009  4.906  95  1310   1\n",
              "1351  0.00  0.00  0.0  0.0  1.01  0.0  ...  0.088  0.000  6.718  33   215   1\n",
              "\n",
              "[2 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyJmoi1fiqAk"
      },
      "source": [
        "## Information about the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "UTTs5MEBoPwR",
        "outputId": "a0b88598-cc3d-4fd7-e77e-540ccd2d87d4"
      },
      "source": [
        "# Previewing the top of the smap dataframe\r\n",
        "spam.head(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1     2    3     4     5   ...    52     53     54   55    56  57\n",
              "0  0.00  0.64  0.64  0.0  0.32  0.00  ...  0.00  0.000  3.756   61   278   1\n",
              "1  0.21  0.28  0.50  0.0  0.14  0.28  ...  0.18  0.048  5.114  101  1028   1\n",
              "\n",
              "[2 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "YTYNbMQYoZlV",
        "outputId": "66e8df4f-3d8a-4e81-fe07-d28b49eb08c1"
      },
      "source": [
        "# Previewing the bottom of the spam dataframe\r\n",
        "spam.tail(2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.97</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1     2    3     4    5    6   ...     51   52   53     54  55  56  57\n",
              "4599  0.96  0.0  0.00  0.0  0.32  0.0  0.0  ...  0.000  0.0  0.0  1.147   5  78   0\n",
              "4600  0.00  0.0  0.65  0.0  0.00  0.0  0.0  ...  0.125  0.0  0.0  1.250   5  40   0\n",
              "\n",
              "[2 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvbjZhhHumlf",
        "outputId": "aded3950-944c-495d-926e-1a1bcdd9d999"
      },
      "source": [
        "# Checking the size of the spam dataset.\r\n",
        "print('The spam dataframe has:(rows,columns)=',spam.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The spam dataframe has:(rows,columns)= (4601, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRqb7lEiz4A4"
      },
      "source": [
        "The spam dataframe contains 4601 rows and 58 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjiw2Jb2vDnS",
        "outputId": "c293708b-0e25-4470-ea7d-0cfffccbf52b"
      },
      "source": [
        "# Checking Columns and Datatypes in the train Dataset.\r\n",
        "print('Information of the spam Dataset')\r\n",
        "print('*' *40)\r\n",
        "spam.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Information of the spam Dataset\n",
            "****************************************\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4601 entries, 0 to 4600\n",
            "Data columns (total 58 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       4601 non-null   float64\n",
            " 1   1       4601 non-null   float64\n",
            " 2   2       4601 non-null   float64\n",
            " 3   3       4601 non-null   float64\n",
            " 4   4       4601 non-null   float64\n",
            " 5   5       4601 non-null   float64\n",
            " 6   6       4601 non-null   float64\n",
            " 7   7       4601 non-null   float64\n",
            " 8   8       4601 non-null   float64\n",
            " 9   9       4601 non-null   float64\n",
            " 10  10      4601 non-null   float64\n",
            " 11  11      4601 non-null   float64\n",
            " 12  12      4601 non-null   float64\n",
            " 13  13      4601 non-null   float64\n",
            " 14  14      4601 non-null   float64\n",
            " 15  15      4601 non-null   float64\n",
            " 16  16      4601 non-null   float64\n",
            " 17  17      4601 non-null   float64\n",
            " 18  18      4601 non-null   float64\n",
            " 19  19      4601 non-null   float64\n",
            " 20  20      4601 non-null   float64\n",
            " 21  21      4601 non-null   float64\n",
            " 22  22      4601 non-null   float64\n",
            " 23  23      4601 non-null   float64\n",
            " 24  24      4601 non-null   float64\n",
            " 25  25      4601 non-null   float64\n",
            " 26  26      4601 non-null   float64\n",
            " 27  27      4601 non-null   float64\n",
            " 28  28      4601 non-null   float64\n",
            " 29  29      4601 non-null   float64\n",
            " 30  30      4601 non-null   float64\n",
            " 31  31      4601 non-null   float64\n",
            " 32  32      4601 non-null   float64\n",
            " 33  33      4601 non-null   float64\n",
            " 34  34      4601 non-null   float64\n",
            " 35  35      4601 non-null   float64\n",
            " 36  36      4601 non-null   float64\n",
            " 37  37      4601 non-null   float64\n",
            " 38  38      4601 non-null   float64\n",
            " 39  39      4601 non-null   float64\n",
            " 40  40      4601 non-null   float64\n",
            " 41  41      4601 non-null   float64\n",
            " 42  42      4601 non-null   float64\n",
            " 43  43      4601 non-null   float64\n",
            " 44  44      4601 non-null   float64\n",
            " 45  45      4601 non-null   float64\n",
            " 46  46      4601 non-null   float64\n",
            " 47  47      4601 non-null   float64\n",
            " 48  48      4601 non-null   float64\n",
            " 49  49      4601 non-null   float64\n",
            " 50  50      4601 non-null   float64\n",
            " 51  51      4601 non-null   float64\n",
            " 52  52      4601 non-null   float64\n",
            " 53  53      4601 non-null   float64\n",
            " 54  54      4601 non-null   float64\n",
            " 55  55      4601 non-null   int64  \n",
            " 56  56      4601 non-null   int64  \n",
            " 57  57      4601 non-null   int64  \n",
            "dtypes: float64(55), int64(3)\n",
            "memory usage: 2.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNJ0bmkIxivr"
      },
      "source": [
        "*The dataset contains 4601 rows, 58 columns and the respective datatypes for each column as shown above.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "TiA5WC0J04O7",
        "outputId": "5d0266da-76cc-44a7-86f8-967bbc6f8613"
      },
      "source": [
        "# Obtaining a description of the dataset.\r\n",
        "spam.describe(include='all')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.104553</td>\n",
              "      <td>0.213015</td>\n",
              "      <td>0.280656</td>\n",
              "      <td>0.065425</td>\n",
              "      <td>0.312223</td>\n",
              "      <td>0.095901</td>\n",
              "      <td>0.114208</td>\n",
              "      <td>0.105295</td>\n",
              "      <td>0.090067</td>\n",
              "      <td>0.239413</td>\n",
              "      <td>0.059824</td>\n",
              "      <td>0.541702</td>\n",
              "      <td>0.093930</td>\n",
              "      <td>0.058626</td>\n",
              "      <td>0.049205</td>\n",
              "      <td>0.248848</td>\n",
              "      <td>0.142586</td>\n",
              "      <td>0.184745</td>\n",
              "      <td>1.662100</td>\n",
              "      <td>0.085577</td>\n",
              "      <td>0.809761</td>\n",
              "      <td>0.121202</td>\n",
              "      <td>0.101645</td>\n",
              "      <td>0.094269</td>\n",
              "      <td>0.549504</td>\n",
              "      <td>0.265384</td>\n",
              "      <td>0.767305</td>\n",
              "      <td>0.124845</td>\n",
              "      <td>0.098915</td>\n",
              "      <td>0.102852</td>\n",
              "      <td>0.064753</td>\n",
              "      <td>0.047048</td>\n",
              "      <td>0.097229</td>\n",
              "      <td>0.047835</td>\n",
              "      <td>0.105412</td>\n",
              "      <td>0.097477</td>\n",
              "      <td>0.136953</td>\n",
              "      <td>0.013201</td>\n",
              "      <td>0.078629</td>\n",
              "      <td>0.064834</td>\n",
              "      <td>0.043667</td>\n",
              "      <td>0.132339</td>\n",
              "      <td>0.046099</td>\n",
              "      <td>0.079196</td>\n",
              "      <td>0.301224</td>\n",
              "      <td>0.179824</td>\n",
              "      <td>0.005444</td>\n",
              "      <td>0.031869</td>\n",
              "      <td>0.038575</td>\n",
              "      <td>0.139030</td>\n",
              "      <td>0.016976</td>\n",
              "      <td>0.269071</td>\n",
              "      <td>0.075811</td>\n",
              "      <td>0.044238</td>\n",
              "      <td>5.191515</td>\n",
              "      <td>52.172789</td>\n",
              "      <td>283.289285</td>\n",
              "      <td>0.394045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.305358</td>\n",
              "      <td>1.290575</td>\n",
              "      <td>0.504143</td>\n",
              "      <td>1.395151</td>\n",
              "      <td>0.672513</td>\n",
              "      <td>0.273824</td>\n",
              "      <td>0.391441</td>\n",
              "      <td>0.401071</td>\n",
              "      <td>0.278616</td>\n",
              "      <td>0.644755</td>\n",
              "      <td>0.201545</td>\n",
              "      <td>0.861698</td>\n",
              "      <td>0.301036</td>\n",
              "      <td>0.335184</td>\n",
              "      <td>0.258843</td>\n",
              "      <td>0.825792</td>\n",
              "      <td>0.444055</td>\n",
              "      <td>0.531122</td>\n",
              "      <td>1.775481</td>\n",
              "      <td>0.509767</td>\n",
              "      <td>1.200810</td>\n",
              "      <td>1.025756</td>\n",
              "      <td>0.350286</td>\n",
              "      <td>0.442636</td>\n",
              "      <td>1.671349</td>\n",
              "      <td>0.886955</td>\n",
              "      <td>3.367292</td>\n",
              "      <td>0.538576</td>\n",
              "      <td>0.593327</td>\n",
              "      <td>0.456682</td>\n",
              "      <td>0.403393</td>\n",
              "      <td>0.328559</td>\n",
              "      <td>0.555907</td>\n",
              "      <td>0.329445</td>\n",
              "      <td>0.532260</td>\n",
              "      <td>0.402623</td>\n",
              "      <td>0.423451</td>\n",
              "      <td>0.220651</td>\n",
              "      <td>0.434672</td>\n",
              "      <td>0.349916</td>\n",
              "      <td>0.361205</td>\n",
              "      <td>0.766819</td>\n",
              "      <td>0.223812</td>\n",
              "      <td>0.621976</td>\n",
              "      <td>1.011687</td>\n",
              "      <td>0.911119</td>\n",
              "      <td>0.076274</td>\n",
              "      <td>0.285735</td>\n",
              "      <td>0.243471</td>\n",
              "      <td>0.270355</td>\n",
              "      <td>0.109394</td>\n",
              "      <td>0.815672</td>\n",
              "      <td>0.245882</td>\n",
              "      <td>0.429342</td>\n",
              "      <td>31.729449</td>\n",
              "      <td>194.891310</td>\n",
              "      <td>606.347851</td>\n",
              "      <td>0.488698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.588000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.310000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.276000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.640000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.706000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.540000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>42.810000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>7.270000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>5.260000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>2.610000</td>\n",
              "      <td>9.670000</td>\n",
              "      <td>5.550000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.410000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.140000</td>\n",
              "      <td>9.090000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>5.450000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>20.830000</td>\n",
              "      <td>16.660000</td>\n",
              "      <td>33.330000</td>\n",
              "      <td>9.090000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>4.760000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>4.760000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.690000</td>\n",
              "      <td>6.890000</td>\n",
              "      <td>8.330000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>4.760000</td>\n",
              "      <td>7.140000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>3.570000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.420000</td>\n",
              "      <td>22.050000</td>\n",
              "      <td>2.170000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.385000</td>\n",
              "      <td>9.752000</td>\n",
              "      <td>4.081000</td>\n",
              "      <td>32.478000</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.829000</td>\n",
              "      <td>1102.500000</td>\n",
              "      <td>9989.000000</td>\n",
              "      <td>15841.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0            1   ...            56           57\n",
              "count  4601.000000  4601.000000  ...   4601.000000  4601.000000\n",
              "mean      0.104553     0.213015  ...    283.289285     0.394045\n",
              "std       0.305358     1.290575  ...    606.347851     0.488698\n",
              "min       0.000000     0.000000  ...      1.000000     0.000000\n",
              "25%       0.000000     0.000000  ...     35.000000     0.000000\n",
              "50%       0.000000     0.000000  ...     95.000000     0.000000\n",
              "75%       0.000000     0.000000  ...    266.000000     1.000000\n",
              "max       4.540000    14.280000  ...  15841.000000     1.000000\n",
              "\n",
              "[8 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70MOsYi-te9_"
      },
      "source": [
        "## Data Cleaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdnSjiC1te-G"
      },
      "source": [
        "### Duplicate and Null Values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPdukKvcte-G",
        "outputId": "cc6c612f-738b-42bd-b76d-8c7d0f96d515"
      },
      "source": [
        "# Checking for duplicates.\r\n",
        "print('Number of duplicated records = ',spam.duplicated().sum())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of duplicated records =  391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z44gNCRate-I"
      },
      "source": [
        "391 duplicates were found in the spam dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Qx9oD3_poZfw",
        "outputId": "87192f99-d7cd-4273-f7fc-419cef8434aa"
      },
      "source": [
        "# Previewing the duplicated data.\r\n",
        "print('The number of duplicated records is=',len(spam[spam.duplicated()]))\r\n",
        "spam[spam.duplicated()].head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of duplicated records is= 391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.44</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.466</td>\n",
              "      <td>22</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.068</td>\n",
              "      <td>131</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.305</td>\n",
              "      <td>0.611</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.529</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.500</td>\n",
              "      <td>22</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.068</td>\n",
              "      <td>131</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.305</td>\n",
              "      <td>0.611</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.529</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.500</td>\n",
              "      <td>22</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1     2    3    4     5   ...     52   53      54   55   56  57\n",
              "26   0.0  0.0  0.00  0.0  0.0  0.00  ...  0.196  0.0   5.466   22   82   1\n",
              "103  0.0  0.0  0.64  0.0  0.0  0.64  ...  0.000  0.0  10.068  131  292   1\n",
              "104  0.0  0.0  0.00  0.0  0.0  0.00  ...  0.000  0.0   5.500   22   66   1\n",
              "105  0.0  0.0  0.64  0.0  0.0  0.64  ...  0.000  0.0  10.068  131  292   1\n",
              "106  0.0  0.0  0.00  0.0  0.0  0.00  ...  0.000  0.0   5.500   22   66   1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk5caS_jpGPl",
        "outputId": "f518efa5-cebc-4ec6-987d-c637639397a4"
      },
      "source": [
        "# Dropping one copy of duplicates\r\n",
        "spam.drop_duplicates(keep='first', inplace = True)\r\n",
        "print('Duplicated records in the dataframe:',spam.duplicated().any())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Duplicated records in the dataframe: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcLIf60vte-J",
        "outputId": "cbed8167-c56c-4ec1-b504-4e8f7cad816c"
      },
      "source": [
        "# Checking for null values.\r\n",
        "spam.isnull().sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     0\n",
              "8     0\n",
              "9     0\n",
              "10    0\n",
              "11    0\n",
              "12    0\n",
              "13    0\n",
              "14    0\n",
              "15    0\n",
              "16    0\n",
              "17    0\n",
              "18    0\n",
              "19    0\n",
              "20    0\n",
              "21    0\n",
              "22    0\n",
              "23    0\n",
              "24    0\n",
              "25    0\n",
              "26    0\n",
              "27    0\n",
              "28    0\n",
              "29    0\n",
              "30    0\n",
              "31    0\n",
              "32    0\n",
              "33    0\n",
              "34    0\n",
              "35    0\n",
              "36    0\n",
              "37    0\n",
              "38    0\n",
              "39    0\n",
              "40    0\n",
              "41    0\n",
              "42    0\n",
              "43    0\n",
              "44    0\n",
              "45    0\n",
              "46    0\n",
              "47    0\n",
              "48    0\n",
              "49    0\n",
              "50    0\n",
              "51    0\n",
              "52    0\n",
              "53    0\n",
              "54    0\n",
              "55    0\n",
              "56    0\n",
              "57    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHpdz82bte-K"
      },
      "source": [
        "No Null values were found in the spam dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gN1gxZytoyJ"
      },
      "source": [
        "# Exploratory Data Analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "tAQuJu13kn0J",
        "outputId": "8888a350-faca-4e35-ce10-e742b9da42ba"
      },
      "source": [
        "# Getting the distribution of the data \r\n",
        "sns.distplot(spam)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb9c04a8090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-MQoh_-m2WU",
        "outputId": "7ebbda84-3293-469a-b23b-4c8af8ba1130"
      },
      "source": [
        "# Kurtosis \r\n",
        "print(spam.kurt())\r\n",
        "print(spam.kurt().sum())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       54.351406\n",
            "1      306.685973\n",
            "2       12.941447\n",
            "3      788.370058\n",
            "4       37.064801\n",
            "5       71.603267\n",
            "6       76.381647\n",
            "7      167.550219\n",
            "8       48.011373\n",
            "9      162.539033\n",
            "10      34.656119\n",
            "11      12.096068\n",
            "12      82.596297\n",
            "13     219.645155\n",
            "14      69.493809\n",
            "15     157.691742\n",
            "16      43.514184\n",
            "17      48.157461\n",
            "18       4.998066\n",
            "19     424.685771\n",
            "20       8.094203\n",
            "21      99.666089\n",
            "22      49.119948\n",
            "23     340.175773\n",
            "24      43.182446\n",
            "25      63.072871\n",
            "26     111.099824\n",
            "27      58.669248\n",
            "28     189.408655\n",
            "29      49.105349\n",
            "30     302.369897\n",
            "31     128.295774\n",
            "32     290.736221\n",
            "33     126.437150\n",
            "34     491.541633\n",
            "35      79.988044\n",
            "36      40.887964\n",
            "37     836.229272\n",
            "38     205.959198\n",
            "39     101.120159\n",
            "40     166.261694\n",
            "41     108.994652\n",
            "42      73.795377\n",
            "43     449.017717\n",
            "44     122.067523\n",
            "45     150.119541\n",
            "46     431.309247\n",
            "47     492.146945\n",
            "48     200.449787\n",
            "49     404.370138\n",
            "50     664.620378\n",
            "51     579.438464\n",
            "52     188.462692\n",
            "53    1238.321018\n",
            "54     614.399885\n",
            "55    1471.215610\n",
            "56     146.108428\n",
            "57      -1.829929\n",
            "dtype: float64\n",
            "13937.462784088542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcOvrbizmZcr",
        "outputId": "a04698c4-69dd-4288-cc6a-e0720040f806"
      },
      "source": [
        "# Skew\r\n",
        "print(spam.skew())\r\n",
        "print(spam.skew().sum())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      5.869855\n",
            "1     13.464664\n",
            "2      2.980623\n",
            "3     27.209539\n",
            "4      4.696946\n",
            "5      6.122653\n",
            "6      6.808707\n",
            "7      9.734232\n",
            "8      5.284306\n",
            "9      8.568579\n",
            "10     5.078281\n",
            "11     2.828005\n",
            "12     6.889952\n",
            "13    11.564142\n",
            "14     7.513375\n",
            "15     9.387745\n",
            "16     5.567668\n",
            "17     5.453867\n",
            "18     1.524251\n",
            "19    15.430174\n",
            "20     2.245707\n",
            "21     9.541533\n",
            "22     5.859524\n",
            "23    15.556682\n",
            "24     5.638834\n",
            "25     6.297471\n",
            "26     9.481582\n",
            "27     6.517998\n",
            "28    11.683591\n",
            "29     6.380831\n",
            "30    13.514852\n",
            "31    10.432463\n",
            "32    13.069355\n",
            "33    10.339838\n",
            "34    16.001762\n",
            "35     7.358775\n",
            "36     5.126620\n",
            "37    27.078694\n",
            "38    11.762303\n",
            "39     9.101847\n",
            "40    11.468806\n",
            "41     9.185157\n",
            "42     7.408226\n",
            "43    18.196824\n",
            "44     8.917866\n",
            "45    10.077034\n",
            "46    19.298485\n",
            "47    18.871757\n",
            "48    13.355885\n",
            "49    14.002666\n",
            "50    21.271982\n",
            "51    18.337278\n",
            "52    10.608970\n",
            "53    31.500180\n",
            "54    22.760655\n",
            "55    31.205495\n",
            "56     8.801641\n",
            "57     0.413450\n",
            "dtype: float64\n",
            "640.6501835738288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "Il7eaToPtfCm",
        "outputId": "5991da27-620a-4e5e-8149-8d7075bf3720"
      },
      "source": [
        "# Visualizing the spam column\r\n",
        "plt.figure(figsize=(12,14))\r\n",
        "sns.countplot(spam.iloc[:,57])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb9c0430490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x1008 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGK6AUH_0dsL"
      },
      "source": [
        "The number of non spam messages was higher than spam messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVxozvxHDnFM"
      },
      "source": [
        "# Naive Bayes Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFaq_5_4jczV"
      },
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eMBGB-hh42n"
      },
      "source": [
        "# Defining X and y.\n",
        "columns = [0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,17, 18, 19, 20,\n",
        "           21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
        "           41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
        "X=spam.iloc[:,0:57]\n",
        "y=spam.iloc[:,57]\n",
        "\n",
        "# Splitting the data.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZQnC140rckd"
      },
      "source": [
        "# Scaling the data.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mu2NRXEmTaH"
      },
      "source": [
        "# Training the model\n",
        "classifier = GaussianNB()  \n",
        "model = classifier.fit(X_train, y_train) \n",
        "\n",
        "# Predicting our test predictors\n",
        "predicted = model.predict(X_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLMhcJbkol7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "99bf1949-dddd-4f17-e1e9-2e50485aa677"
      },
      "source": [
        "#Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "gbpred= pd.DataFrame({'actual': y_test, 'predicted': y_pred})\n",
        "gbpred.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4061</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3150</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      actual  predicted\n",
              "4061       0          1\n",
              "2379       0          0\n",
              "2709       0          0\n",
              "210        1          1\n",
              "3150       0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo83oHbEI3OL",
        "outputId": "a9eabe19-de25-4df2-8430-88af358a4f2b"
      },
      "source": [
        "# Measuring the accuracy of the model\r\n",
        "import sklearn.metrics as metrics\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "print(f'Accuracy score =: {accuracy_score(y_test, y_pred)} ,f1 score = {f1_score(y_test, y_pred)}')\r\n",
        "print(f'{classification_report(y_test, y_pred)}')\r\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score =: 0.8123515439429929 ,f1 score = 0.8073170731707316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.71      0.82       495\n",
            "           1       0.70      0.95      0.81       347\n",
            "\n",
            "    accuracy                           0.81       842\n",
            "   macro avg       0.83      0.83      0.81       842\n",
            "weighted avg       0.85      0.81      0.81       842\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[353, 142],\n",
              "       [ 16, 331]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pf5_VKalAo9"
      },
      "source": [
        "* The initial model for Naive Bayes had an accuracy of 81.2% and an F1 score of 80.7%.\r\n",
        "\r\n",
        "* The Confusion Matrix suggested 353 and 331 accurate predictions and, 142 and 16 inaccurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhtIeTr1cZRU",
        "outputId": "5d932569-e034-4ee7-ca2d-69ee038b5a57"
      },
      "source": [
        "# Assessing the errors\r\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \r\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \r\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.1876484560570071\n",
            "Mean Squared Error: 0.1876484560570071\n",
            "Root Mean Squared Error: 0.4331840902630279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzI1tH9qMseE"
      },
      "source": [
        "## 70 - 30 Split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "31tp6aibM2AP",
        "outputId": "e6fc50e5-70e0-47a2-9c04-af51ff634cc7"
      },
      "source": [
        "# Splitting the data.\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\r\n",
        "\r\n",
        "# Scaling the data.\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "X_train = scaler.transform(X_train)\r\n",
        "X_test = scaler.transform(X_test)\r\n",
        "\r\n",
        "# Training the model\r\n",
        "classifier = GaussianNB()  \r\n",
        "model = classifier.fit(X_train, y_train) \r\n",
        "\r\n",
        "# Predicting our test predictors\r\n",
        "predicted = model.predict(X_test)\r\n",
        "\r\n",
        "#Making predictions\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "gbpred= pd.DataFrame({'actual': y_test, 'predicted': y_pred})\r\n",
        "gbpred.head()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4061</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3150</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      actual  predicted\n",
              "4061       0          1\n",
              "2379       0          0\n",
              "2709       0          0\n",
              "210        1          1\n",
              "3150       0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7KIiWE0Ndea",
        "outputId": "7ebca49c-10ac-4374-b0a7-dc9bc622b6fd"
      },
      "source": [
        "# Measuring the accuracy of the model\r\n",
        "print(f'Accuracy score =: {accuracy_score(y_test, y_pred)} ,f1 score = {f1_score(y_test, y_pred)}')\r\n",
        "print(f'{classification_report(y_test, y_pred)}')\r\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score =: 0.8297703879651623 ,f1 score = 0.826192400970089\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.73      0.83       737\n",
            "           1       0.72      0.97      0.83       526\n",
            "\n",
            "    accuracy                           0.83      1263\n",
            "   macro avg       0.85      0.85      0.83      1263\n",
            "weighted avg       0.87      0.83      0.83      1263\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[537, 200],\n",
              "       [ 15, 511]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Y52QlVOsqB"
      },
      "source": [
        "* The 70-30 split model for Naive Bayes had an accuracy of 82.9% and an F1 score of 82.6%.\r\n",
        "\r\n",
        "* The Confusion Matrix suggested 537 and 511 accurate predictions and, 200 and 15 inaccurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UHnkyuaOsqM",
        "outputId": "3bf9a95d-c0ed-4449-bfe9-2c51d9baca85"
      },
      "source": [
        "# Assessing the errors\r\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \r\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \r\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.1702296120348377\n",
            "Mean Squared Error: 0.1702296120348377\n",
            "Root Mean Squared Error: 0.41258891409590454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r06cgmP_PHEo"
      },
      "source": [
        "## 60 - 40 Split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tX-sUgthPHEo",
        "outputId": "c8fbf104-12ef-49f6-c71e-25a7ab7682cf"
      },
      "source": [
        "# Splitting the data.\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\r\n",
        "\r\n",
        "# Scaling the data.\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "X_train = scaler.transform(X_train)\r\n",
        "X_test = scaler.transform(X_test)\r\n",
        "\r\n",
        "# Training the model\r\n",
        "classifier = GaussianNB()  \r\n",
        "model = classifier.fit(X_train, y_train) \r\n",
        "\r\n",
        "# Predicting our test predictors\r\n",
        "predicted = model.predict(X_test)\r\n",
        "\r\n",
        "#Making predictions\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "gbpred= pd.DataFrame({'actual': y_test, 'predicted': y_pred})\r\n",
        "gbpred.head()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4061</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3150</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      actual  predicted\n",
              "4061       0          1\n",
              "2379       0          0\n",
              "2709       0          0\n",
              "210        1          1\n",
              "3150       0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUXxOXdxPHEp",
        "outputId": "661a4ed3-a96f-418f-ad1f-36d46856460d"
      },
      "source": [
        "# Measuring the accuracy of the model\r\n",
        "print(f'Accuracy score =: {accuracy_score(y_test, y_pred)} ,f1 score = {f1_score(y_test, y_pred)}')\r\n",
        "print(f'{classification_report(y_test, y_pred)}')\r\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score =: 0.8200712589073634 ,f1 score = 0.814678899082569\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.72      0.83       994\n",
            "           1       0.70      0.97      0.81       690\n",
            "\n",
            "    accuracy                           0.82      1684\n",
            "   macro avg       0.84      0.84      0.82      1684\n",
            "weighted avg       0.86      0.82      0.82      1684\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[715, 279],\n",
              "       [ 24, 666]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_1u5xtfPHEq"
      },
      "source": [
        "* The 60-40 split model for Naive Bayes had an accuracy of 82.0% and an F1 score of 81.5%.\r\n",
        "\r\n",
        "* The Confusion Matrix suggested 715 and 666 accurate predictions and, 279 and 24 inaccurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCibW_GhPHEq",
        "outputId": "63a4e646-d604-4c09-aeee-301db0dc1e02"
      },
      "source": [
        "# Assessing the errors\r\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \r\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \r\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.17992874109263657\n",
            "Mean Squared Error: 0.17992874109263657\n",
            "Root Mean Squared Error: 0.4241800809710854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9_k-AbJQdqL"
      },
      "source": [
        "The 70-30 split generated the best model compared to the other models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkxGrk3DmWi6"
      },
      "source": [
        "## Hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB7Ot2t7eHc_",
        "outputId": "37fbd408-b273-432f-8f56-a1c17bd86fc0"
      },
      "source": [
        "# Getting best parameters\r\n",
        "\r\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "from sklearn.preprocessing import PowerTransformer\r\n",
        "from sklearn import preprocessing\r\n",
        "cv_method = RepeatedStratifiedKFold(n_splits=5, \r\n",
        "                                    n_repeats=3, \r\n",
        "                                    random_state=0)\r\n",
        "nb_classifier = GaussianNB()\r\n",
        "\r\n",
        "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\r\n",
        "gs_NB = GridSearchCV(estimator=nb_classifier, \r\n",
        "                 param_grid=params_NB, \r\n",
        "                 cv=cv_method,   # use any cross validation technique \r\n",
        "                 verbose=1, \r\n",
        "                 scoring='accuracy') \r\n",
        "gs_NB.fit(X_train, y_train)\r\n",
        "\r\n",
        "gs_NB.best_params_"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1500 out of 1500 | elapsed:    5.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'var_smoothing': 0.0004328761281083057}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88RGP7tKX82q"
      },
      "source": [
        "## 70 - 30 Split with Hyperparameter Tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Dtnn1T6xX821",
        "outputId": "3c933ec9-78e2-433a-e289-f997c2b74173"
      },
      "source": [
        "# Splitting the data.\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\r\n",
        "\r\n",
        "# Scaling the data.\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "X_train = scaler.transform(X_train)\r\n",
        "X_test = scaler.transform(X_test)\r\n",
        "\r\n",
        "# Training the model\r\n",
        "classifier = GaussianNB(var_smoothing= 0.0001)  \r\n",
        "model = classifier.fit(X_train, y_train) \r\n",
        "\r\n",
        "# Predicting our test predictors\r\n",
        "predicted = model.predict(X_test)\r\n",
        "\r\n",
        "#Making predictions\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "gbpred= pd.DataFrame({'actual': y_test, 'predicted': y_pred})\r\n",
        "gbpred.head()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4061</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3150</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      actual  predicted\n",
              "4061       0          1\n",
              "2379       0          0\n",
              "2709       0          0\n",
              "210        1          1\n",
              "3150       0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ieTHDRbX822",
        "outputId": "4e93bcfd-9b60-4c33-bcb6-20f3179c3b7b"
      },
      "source": [
        "# Measuring the accuracy of the model\r\n",
        "print(f'Accuracy score =: {accuracy_score(y_test, y_pred)} ,f1 score = {f1_score(y_test, y_pred)}')\r\n",
        "print(f'{classification_report(y_test, y_pred)}')\r\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score =: 0.8297703879651623 ,f1 score = 0.826192400970089\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.73      0.83       737\n",
            "           1       0.72      0.97      0.83       526\n",
            "\n",
            "    accuracy                           0.83      1263\n",
            "   macro avg       0.85      0.85      0.83      1263\n",
            "weighted avg       0.87      0.83      0.83      1263\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[537, 200],\n",
              "       [ 15, 511]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCiFTD9_X823",
        "outputId": "f8897880-1c26-4423-8f92-38f6319151d5"
      },
      "source": [
        "# Assessing the errors\r\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \r\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \r\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.1702296120348377\n",
            "Mean Squared Error: 0.1702296120348377\n",
            "Root Mean Squared Error: 0.41258891409590454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxEfqGK4X823"
      },
      "source": [
        "* The 70-30 split model with hyperparameter tuning for KNN had an accuracy of 82.9% and an F1 score of 82.6%.\r\n",
        "\r\n",
        "* The Confusion Matrix suggested 537 and 511 accurate predictions and, 200 and 15 inaccurate predictions.\r\n",
        "\r\n",
        "* There was no improvement with hyperparameter tuning. It is recommended to use the 70-30 split model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVFor-G8a2B_"
      },
      "source": [
        "## Challenging the Solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfr26erHa9i9",
        "outputId": "41db0a50-55ed-4fb2-dd07-69e4d0690cd0"
      },
      "source": [
        "# Reviewing the Solution \r\n",
        "# compare algorithms\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "\r\n",
        "\r\n",
        "# Declaring our X and y variables\r\n",
        "X=spam.iloc[:,0:57]\r\n",
        "y=spam.iloc[:,57]\r\n",
        "\r\n",
        "# Splitting the data into training and test sets,\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\r\n",
        "\r\n",
        "# Spot Check Algorithms\r\n",
        "models = []\r\n",
        "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\r\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\r\n",
        "models.append(('KNN', KNeighborsClassifier()))\r\n",
        "models.append(('CART', DecisionTreeClassifier()))\r\n",
        "models.append(('RF', RandomForestClassifier()))\r\n",
        "models.append(('GBC', GradientBoostingClassifier()))\r\n",
        "models.append(('NB', GaussianNB()))\r\n",
        "models.append(('SVM', SVC(gamma='auto')))\r\n",
        "# evaluate each model in turn\r\n",
        "# evaluate each model in turn\r\n",
        "results = []\r\n",
        "names = []\r\n",
        "for name, model in models:\r\n",
        "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\r\n",
        "\tcv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\r\n",
        "\tresults.append(cv_results)\r\n",
        "\tnames.append(name)\r\n",
        "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR: 0.926364 (0.011940)\n",
            "LDA: 0.889550 (0.008462)\n",
            "KNN: 0.790971 (0.016215)\n",
            "CART: 0.905286 (0.014556)\n",
            "RF: 0.947749 (0.013659)\n",
            "GBC: 0.939729 (0.011720)\n",
            "NB: 0.826908 (0.017153)\n",
            "SVM: 0.812354 (0.017671)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY6b51lt2dQO"
      },
      "source": [
        "Conclusion\r\n",
        "\r\n",
        "The best model for classifying messages as spam would be the Random Forest which would have an accuracy of 94.8% which is higher than the Naive Bayes classifier of 82.9%."
      ]
    }
  ]
}